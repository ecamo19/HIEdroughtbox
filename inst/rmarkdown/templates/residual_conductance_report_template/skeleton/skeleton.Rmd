---
title: 'Species Name'
author: 'Your Name'
date: '`r format(Sys.time(), '%d %B, %Y')`'
output:
  prettydoc::html_pretty:
    highlight: pygments
    theme: cayman
    toc: yes
    number_sections: no
    toc_depth: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = "", 
                      fig.align = 'center',
					  fig.width = 11, fig.height = 7)
```

```{r, setup_wd, include=FALSE}
# Set knit directory
knitr::opts_knit$set(root.dir = 'path/to/root/dir')
```

```{r knitr, include = FALSE}

# Save figures in specific place
knitr::opts_chunk$set(autodep        = TRUE,
                      cache          = FALSE,
                      cache.comments = TRUE,
                      
                      # Save figures as pdf ?
                      #dev = c( "png", "pdf"),
                  
                      # Include code?
                      echo           = TRUE,
                      error          = FALSE,
                      fig.align      = "center",
                      
                      # Path where figures are going to be store pdf single 
                      # figures
                      Edit path in line 44 and comment out this line   
                      fig.path       = paste0("./figures_[sp_name]_gres", "/"),
                      fig.width      = 11,
                      fig.height     = 7,
                      message        = FALSE,
                      warning        = FALSE)
```

```{r cleanup-docs, cache = FALSE,echo = FALSE}
# save a html copy file in a specific place
# doc.files <- c(list.files(pattern = "pdf"),
#                list.files(pattern = "html"),
#                list.files(pattern = "docx"))
# 
# for (file in doc.files) {   
#     file.rename(file, file.path("../../[insert_folder_name]/", file))
# }
```

```{r libaries, message = FALSE, warning = FALSE, cache = FALSE}
library(HIEdroughtbox)

# For data manipulation
library(dplyr)
library(ggplot2)
library(purrr)
library(stringr)
library(tidyr)

# For running python in Rmarkdown
library(reticulate)
library(here)

# For reading xlsx file
library(readxl)
```

```{r}
# Set conda env for working with python
use_condaenv("/home/ecamo19/Documents/openssl/envs/r-reticulate")
```

# 1. Load Droughtbox data

```{r, raw_data_list}

# Create list with all data frameslibrary(HIEdroughtbox)

# For data manipulation
library(dplyr)
library(ggplot2)
library(purrr)
library(stringr)
library(tidyr)

# For running python in Rmarkdown
library(reticulate)
library(here)
[sp_name]_raw_data <- read_hie_droughtbox_data_folder("./")
```

```{r}

# Show the names of each element in the list
names([sp_name]_raw_data)
```

# 2. Data preprocessing

## Plot climatic data

```{r, plot_climatic_controls}
map([sp_name]_raw_data, plot_droughtbox_climatic_controls)
```

## Plot raw droughtbox data

```{r, plot_raw_data}
map([sp_name]_raw_data, plot_strains_weights)
```

## Clean data

### File 1

```{r}
#[sp_name]_25c_cleaned <- 
    
    # Select the data to be clean
    [sp_name]_raw_data["file_name_25c.dat"] %>% 
    
    # Transform list element to dataframe type
    as.data.frame(.) %>%

    # clean colnames
    `colnames<-`(str_extract(colnames(.), '\\b\\w+$')) %>%

   # Choose a interval of time
    filter_droughtbox_data(.,
                           from_start_time = "HH:MM:SS",
                           to_end_time = "HH:MM:SS") %>% 
    # Clean the data
    clean_droughtbox_data(.,
                          remove_n_observations = 5,
                          threshold = 0.2)
```

### Plot cleaned data

```{r, plot_cleaned_data_25c}
plot_strains_weights([sp_name]_25c_cleaned, show_tare_group = FALSE)
```

### File 2

```{r}
#[sp_name]_30c_cleaned <- 
    
    # Select the data to be clean
    [sp_name]_raw_data["file_name_30c.dat"] %>% 
    
    # Transform list element to dataframe type
    as.data.frame(.) %>%

    # clean colnames
    `colnames<-`(str_extract(colnames(.), '\\b\\w+$')) %>%

    # Choose a interval of time
    filter_droughtbox_data(.,
                           from_start_time = "HH:MM:SS",
                           to_end_time = "HH:MM:SS") %>% 
    # Clean the data
    clean_droughtbox_data(.,
                          remove_n_observations = 5,
                          threshold = 0.2)
    
```

### Plot cleaned data

```{r, plot_cleaned_data_30c}
plot_strains_weights([sp_name]_30c_cleaned, show_tare_group = FALSE)
```

### File 3

```{r}
#[sp_name]_35c_cleaned <- 
    
    # Select the data to be clean
    [sp_name]_raw_data["file_name_35c.dat"] %>% 
    
    # Transform list element to dataframe type
    as.data.frame(.) %>%

    # clean colnames
    `colnames<-`(str_extract(colnames(.), '\\b\\w+$')) %>%

    # Choose a interval of time
    filter_droughtbox_data(.,
                           from_start_time = "HH:MM:SS",
                           to_end_time = "HH:MM:SS") %>% 
    # Clean the data
    clean_droughtbox_data(.,
                          remove_n_observations = 5,
                          threshold = 0.2)
    
```

### Plot cleaned data

```{r, plot_cleaned_data_35c}
plot_strains_weights([sp_name]_35c_cleaned, show_tare_group = FALSE)
```

### File 4

```{r}
#[sp_name]_40c_cleaned <- 
    
    # Select the data to be clean
    [sp_name]_raw_data["file_name_40c.dat"] %>% 
    
    # Transform list element to dataframe type
    as.data.frame(.) %>%

    # clean colnames
    `colnames<-`(str_extract(colnames(.), '\\b\\w+$')) %>%

    # Choose a interval of time
    filter_droughtbox_data(.,
                           from_start_time = "HH:MM:SS",
                           to_end_time = "HH:MM:SS") %>% 
    # Clean the data
    clean_droughtbox_data(.,
                          remove_n_observations = 5,
                          threshold = 0.2)
    
```

### Plot cleaned data

```{r, plot_cleaned_data_40c}
plot_strains_weights([sp_name]_40c_cleaned, show_tare_group = FALSE)
```

### File 5

```{r}
#[sp_name]_45c_cleaned <- 
    
    # Select the data to be clean
    [sp_name]_raw_data["file_name_45c.dat"] %>% 
    
    # Transform list element to dataframe type
    as.data.frame(.) %>%

    # clean colnames
    `colnames<-`(str_extract(colnames(.), '\\b\\w+$')) %>%

   # Choose a interval of time
    filter_droughtbox_data(.,
                           from_start_time = "HH:MM:SS",
                           to_end_time = "HH:MM:SS") %>% 
    # Clean the data
    clean_droughtbox_data(.,
                          remove_n_observations = 5,
                          threshold = 0.2)
```

### Plot cleaned data

```{r, plot_cleaned_data_45c}
plot_strains_weights([sp_name]_45c_cleaned, show    read.csv("./euc_crebra_images/cropped_images_for_imagej/areas_cm2.csv",
                header = TRUE)  %>%

    # Separate file name from file extension
    separate_wider_delim(file_name,
                        delim = ".",
                        names = c("file_name", "file_extension")) %>%

    # Separate column into 5 based on _
    separate(., col = file_name,
            into = c('image', 'genera', 'specie', 'tree_id',  'set_temperature'),
            sep = '_') %>%

    # Unite Genera and specie columns
    unite("spcode", genera:specie, sep = "_", remove = TRUE) %>%

    # Remove unused columns
    select(-c(file_extension, image)) %>%

    # Remove leading zeros inside column
    mutate(tree_id = factor(str_remove(tree_id, "^0+")),

           # Remove the last character in set_temperature column
           set_temperature = factor(str_sub(set_temperature, end = -2)))_tare_group = FALSE)
```

### File 6

```{r}
#[sp_name]_50c_cleaned <- 
    
    # Select the data to be clean
    [sp_name]_raw_data["file_name_50c.dat"] %>% 
    
    # Transform list element to dataframe type
    as.data.frame(.) %>%

    # clean colnames
    `colnames<-`(str_extract(colnames(.), '\\b\\w+$')) %>%

   # Choose a interval of time
    filter_droughtbox_data(.,
                           from_start_time = "HH:MM:SS",
                           to_end_time = "HH:MM:SS") %>% 
    # Clean the data
    clean_droughtbox_data(.,
                          remove_n_observations = 5,
                          threshold = 0.2)
```

### Plot cleaned data

```{r, plot_cleaned_data_50c}
plot_strains_weights([sp_name]_50c_cleaned, show_tare_group = FALSE)
```

### File 7

```{r}
#[sp_name]_55c_cleaned <- 
    
    # Select the data to be clean
    [sp_name]_raw_data["file_name_55c.dat"] %>% 
    
    # Transform list element to dataframe type
    as.data.frame(.) %>%

    # clean colnames
    `colnames<-`(str_extract(colnames(.), '\\b\\w+$')) %>%

    # Choose a interval of time
    filter_droughtbox_data(.,
                           from_start_time = "HH:MM:SS",
                           to_end_time = "HH:MM:SS") %>% 
    # Clean the data
    clean_droughtbox_data(.,
                          remove_n_observations = 5,
                          threshold = 0.2)
```

### Plot cleaned data

```{r, plot_cleaned_data_55c}
plot_strains_weights([sp_name]_55c_cleaned, show_tare_group = FALSE)
```

## Merge cleaned dataframes

```{r}
#[sp_name]_cleaned_data <- 
                    merge_droughtbox_data([sp_name]_25c_cleaned,
                                          [sp_name]_30c_cleaned,
                                          [sp_name]_35c_cleaned,
                                          [sp_name]_40c_cleaned,
                                          [sp_name]_45c_cleaned,
                                          [sp_name]_50c_cleaned,
                                          [sp_name]_55c_cleaned)
```

# 3. Calculate Branch areas

```{python, python_code, echo=FALSE}
import cv2
import os
import shutil
from os.path import join
from os import listdir
import pathlib

# Function for cropping images
def crop_images_for_imagej(path, blur = 25):

    # Validate inputs ---------------------------------------------------------

    # Make sure dir exists
    if not os.path.isdir(path):
        raise ValueError(
            f'Directory: {path} not found exist. Check presence or spelling'
        )

    # Crop images -------------------------------------------------------------

    # Set working directory
    os.chdir(path)

    # Set image coordiantes for removing 2x2 squared tag in all images.
    # The coordinates were obtained using gThumb
    width = 2504
    height = 2961
    x = 46
    y = 546

    file_count = 0

    # Overwrite folder if does exists
    if os.path.exists('../cropped_images_for_imagej'):
        print("Overwrinting cropped_images_for_imagej folder")
        shutil.rmtree('../cropped_images_for_imagej')
        os.mkdir('../cropped_images_for_imagej')

    # Create folder to store the cropped images
    elif not os.path.isdir('../cropped_images_for_imagej'):
            os.mkdir('../cropped_images_for_imagej')

    else:
       raise ValueError(
            print("Failed creating cropped_images_for_imagej folder")
        )

    # Loop over each file
    for each_file in listdir(path):

        if each_file.endswith('.jpg'):

            # Create path to image
            image_path = join(path, each_file)

            print(f'Cropping: {each_file}')

            # Read image
            img = cv2.imread(image_path, 0)

            # Crop image
            cropped_image = img[y:y + height, x:x + width]

            # Apply filter to image for improving quality
            cropped_image = cv2.medianBlur(cropped_image, blur)

            # Save image
            cv2.imwrite(f'../cropped_images_for_imagej/cropped_{each_file}', cropped_image)

            # Count the number of files read
            file_count += 1

        else:
            print(f'{each_file} is not jpg file')

    print(f'Total number of images cropped: {file_count}')


    # Generate a full path to cropped images folder which will be use in
    # imagej macro

    print("\nUse the following path for the ImageJ macro:")
    path_to_cropped_images_folder = os.path.dirname(os.path.abspath("../cropped_images_for_imagej"))
    print(f'{path_to_cropped_images_folder}/cropped_images_for_imagej')

    # Save ImageJ code as .ijm ------------------------------------------------

    # Check if file exist
    if os.path.exists("../leaf_area_300dpi.ijm"):

        print(f'\nMacro Code for ImageJ already exist')

    # Create file
    else:
        imagej_macro_file = open(f"../leaf_area_300dpi.ijm", "x")

        # Write code to file
        imagej_macro_file.write('''

// Description -----------------------------------------------------------------
//
// ImageJ macro for calculating the area (cm2) of scanned leaves at a resolution
// of 300 dpi.
//
// This macro is meant to be run in headless mode using Fiji
//
// Download Fiji from: https://imagej.net/software/fiji/downloads
//
// The function takes 1 parameter (i.e. path/to/folder) which is the full path
// where .jpg scans are saved locally.
//
// The function returns a .csv file containing the name of the image file and
// the area in cm2
//
// Examples of a input_path ----------------------------------------------------
//
// VALID input path
//
// input_path = "/home/images_for_imagej"
//
// INVALID input paths
//
// input_path = "./cropped_images_for_imagej"
//
// Not recommended
// Notice the "/" at the end of the path
//
// input_path = "/home/images_for_imagej/"

// Get input path --------------------------------------------------------------
print("Remember to provide the full path");
input_path = getArgument();
print("Reading files inside "+input_path);

// Set working directory -------------------------------------------------------
File.setDefaultDir(input_path)

//1- Function for calculating the leaf area ------------------------------------
function leaf_area(){
            var dpi = 300;

            // 300 dpi
            var pixels_per_centimeter = dpi / 2.54;

            // ImageJ functions
            run("Clear Results");
            run("Set Scale...", "distance=" + pixels_per_centimeter + " known=1 pixel=1 unit=cm");
            run("Make Binary");
            run("Create Selection");
            run("Set Measurements...", "area redirect=None decimal=3");
            run("Analyze Particles...", "size=0-Infinity circularity=0.00-1.00 show=Nothing display clear");
            run("Summarize");

            // This will get the last line of the results, the max
            var area_cm2 = getResult("Area");

			// Get image name
			var image_name = getTitle();

			// Combine file name and area
			var result = image_name + "," +area_cm2;
			return result;
			}

//2- Function for reading and processing each image ----------------------------
function process_file(input, file){

	// Create full path to file
	input_path = input + File.separator + file;

	// Open images and get the leaf area
	if(endsWith(input, file_extension))
		showProgress(i+1, list.length);

		// Open image
		open(input_path);

		// Calculate Leaf area and append results to file
		File.append(leaf_area(), output_path);

		// Close each each
		close();

	// Return error if something goes wrong
	//else {print("Failed processiing file.");}
	}

//3- Get the area of each file -------------------------------------------------
process_folder(input_path);

	function process_folder(input){

		// Define the file images' file extention to read
		file_extension = ".jpg";

		// Create output file inside input folder
		output_path = input + File.separator + "areas_cm2.csv";

		// Create header to the output file
		headline = "file_name, area";

		// Append header to output file
		File.append(headline, output_path);

		// Get each file stored in the input folder
		list = getFileList(input);

		// Print total number of files inside folder
		print(list.length+" files found inside "+ input_path);

		// Loop over the files found in the input folder
		for (i = 0; i < list.length; i++) {

			// Read folders
			//if (endsWith(list[i], "/"))
			//	process_folder(input + File.separator + list[i]);

			// Process each file
			if(endsWith(list[i], file_extension)){
			process_file(input, list[i]);}

			else{print("Warning! Failed processing "+list[i]+". Files must have a "+file_extension + " extension");}

		}
		print("Done! Output file created at:"+output_path);
	}
''')
        # Close file
        imagej_macro_file.close()
        print('\nMacro code for ImageJ created')
```

## Use python function to crop images

```{python}
path = "path/to/scanned_images"
crop_images_for_imagej(path = path)
```

## Calculate leaf area using ImageJ macro in bash

```{bash, bash_code, results = "hide"}
pwd
# Enter the path where Fiji was installed
# Locate leaf_area_300dpi.ijm macro
# Copy path to cropped_images_for_imagej


# ~/path/to/fiji-linux64/ImageJ-linux64 --headless --console -macro path/to/leaf_area_300dpi.ijm 'path/to/cropped_images_for_imagej'
```

# 4. Calculate Residual conductance

## Load Areas data

```{r}
[sp_name]_areas_data <-
    read.csv("./path/to/cropped_images_for_imagej/areas_cm2.csv",
                header = TRUE)  %>%

    # Separate file name from file extension
    separate_wider_delim(file_name,
                         delim = ".",
                         names = c("file_name", "file_extension")) %>%

    # Separate column into 5 based on _
    separate(., col = file_name,
             into = c('image', 'genera', 'specie', 'tree_id',  'set_temperature'),
             sep = '_') %>%

    # Unite Genera and specie columns
    unite("spcode", genera:specie, sep = "_", remove = TRUE) %>%

    # Remove unused columns
    select(-c(file_extension, image)) %>%

    # Remove leading zeros inside column
    mutate(tree_id = factor(str_remove(tree_id, "^0+")),

           # Remove the last character in set_temperature column
           set_temperature = factor(str_sub(set_temperature, end = -2)))
```

## Load dry weights data

```{r}
[sp_name]_dry_weights_data <- read_excel("./[sp_name]_dry_weights.xlsx")
```

### Merge area and dry weights dataframes

```{r}
[sp_name]_dry_weights_areas_data <- 
    inner_join([sp_name]_dry_weights_data, [sp_name]_areas_data,
               by = join_by(spcode, tree_id, set_temperature))
```

## Calculate Residual conductance

```{r}
calculate_residual_conductance(droughtbox_data =  [sp_name]_cleaned_data,
                               leaf_and_branch_area_data = [sp_name]_dry_weights_areas_data)

```


